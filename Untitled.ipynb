{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fer2013.csv')\n",
    "\n",
    "# print(df.info())\n",
    "# print(df[\"Usage\"].value_counts())\n",
    "\n",
    "# print(df.head())\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "449/449 [==============================] - 309s 688ms/step - loss: 1.7191 - accuracy: 0.3013 - val_loss: 1.5378 - val_accuracy: 0.3998\n",
      "Epoch 2/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 1.5114 - accuracy: 0.4059 - val_loss: 1.3914 - val_accuracy: 0.4550\n",
      "Epoch 3/200\n",
      "449/449 [==============================] - 231s 515ms/step - loss: 1.4001 - accuracy: 0.4563 - val_loss: 1.3248 - val_accuracy: 0.4834\n",
      "Epoch 4/200\n",
      "449/449 [==============================] - 236s 525ms/step - loss: 1.3377 - accuracy: 0.4818 - val_loss: 1.2509 - val_accuracy: 0.5127\n",
      "Epoch 5/200\n",
      "449/449 [==============================] - 235s 524ms/step - loss: 1.2846 - accuracy: 0.5058 - val_loss: 1.2365 - val_accuracy: 0.5241\n",
      "Epoch 6/200\n",
      "449/449 [==============================] - 236s 526ms/step - loss: 1.2595 - accuracy: 0.5171 - val_loss: 1.2255 - val_accuracy: 0.5266\n",
      "Epoch 7/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 1.2360 - accuracy: 0.5268 - val_loss: 1.2237 - val_accuracy: 0.5244\n",
      "Epoch 8/200\n",
      "449/449 [==============================] - 236s 525ms/step - loss: 1.2056 - accuracy: 0.5384 - val_loss: 1.1909 - val_accuracy: 0.5425\n",
      "Epoch 9/200\n",
      "449/449 [==============================] - 235s 522ms/step - loss: 1.1858 - accuracy: 0.5426 - val_loss: 1.1942 - val_accuracy: 0.5391\n",
      "Epoch 10/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 1.1622 - accuracy: 0.5539 - val_loss: 1.1775 - val_accuracy: 0.5447\n",
      "Epoch 11/200\n",
      "449/449 [==============================] - 235s 523ms/step - loss: 1.1433 - accuracy: 0.5618 - val_loss: 1.1676 - val_accuracy: 0.5503\n",
      "Epoch 12/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 1.1232 - accuracy: 0.5712 - val_loss: 1.1598 - val_accuracy: 0.5676\n",
      "Epoch 13/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 1.1137 - accuracy: 0.5736 - val_loss: 1.1606 - val_accuracy: 0.5584\n",
      "Epoch 14/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 1.0921 - accuracy: 0.5793 - val_loss: 1.1732 - val_accuracy: 0.5531\n",
      "Epoch 15/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 1.0792 - accuracy: 0.5913 - val_loss: 1.1473 - val_accuracy: 0.5639\n",
      "Epoch 16/200\n",
      "449/449 [==============================] - 223s 496ms/step - loss: 1.0585 - accuracy: 0.5970 - val_loss: 1.1532 - val_accuracy: 0.5701\n",
      "Epoch 17/200\n",
      "449/449 [==============================] - 220s 490ms/step - loss: 1.0401 - accuracy: 0.5994 - val_loss: 1.1659 - val_accuracy: 0.5634\n",
      "Epoch 18/200\n",
      "449/449 [==============================] - 232s 516ms/step - loss: 1.0321 - accuracy: 0.6065 - val_loss: 1.1656 - val_accuracy: 0.5659\n",
      "Epoch 19/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 1.0171 - accuracy: 0.6089 - val_loss: 1.1498 - val_accuracy: 0.5564\n",
      "Epoch 20/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.9997 - accuracy: 0.6207 - val_loss: 1.1509 - val_accuracy: 0.5743\n",
      "Epoch 21/200\n",
      "449/449 [==============================] - 234s 522ms/step - loss: 0.9806 - accuracy: 0.6261 - val_loss: 1.1635 - val_accuracy: 0.5609\n",
      "Epoch 22/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.9697 - accuracy: 0.6319 - val_loss: 1.1397 - val_accuracy: 0.5790\n",
      "Epoch 23/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.9501 - accuracy: 0.6391 - val_loss: 1.1659 - val_accuracy: 0.5726\n",
      "Epoch 24/200\n",
      "449/449 [==============================] - 235s 522ms/step - loss: 0.9406 - accuracy: 0.6407 - val_loss: 1.1542 - val_accuracy: 0.5678\n",
      "Epoch 25/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.9327 - accuracy: 0.6449 - val_loss: 1.1768 - val_accuracy: 0.5740\n",
      "Epoch 26/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.9184 - accuracy: 0.6499 - val_loss: 1.1555 - val_accuracy: 0.5715\n",
      "Epoch 27/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.9066 - accuracy: 0.6543 - val_loss: 1.1820 - val_accuracy: 0.5592\n",
      "Epoch 28/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.8889 - accuracy: 0.6649 - val_loss: 1.2177 - val_accuracy: 0.5584\n",
      "Epoch 29/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.8835 - accuracy: 0.6627 - val_loss: 1.2090 - val_accuracy: 0.5701\n",
      "Epoch 30/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.8658 - accuracy: 0.6721 - val_loss: 1.1962 - val_accuracy: 0.5681\n",
      "Epoch 31/200\n",
      "449/449 [==============================] - 232s 518ms/step - loss: 0.8590 - accuracy: 0.6738 - val_loss: 1.1778 - val_accuracy: 0.5756\n",
      "Epoch 32/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.8495 - accuracy: 0.6790 - val_loss: 1.1895 - val_accuracy: 0.5726\n",
      "Epoch 33/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.8333 - accuracy: 0.6863 - val_loss: 1.1995 - val_accuracy: 0.5698\n",
      "Epoch 34/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.8344 - accuracy: 0.6825 - val_loss: 1.2074 - val_accuracy: 0.5723\n",
      "Epoch 35/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.8040 - accuracy: 0.6949 - val_loss: 1.2278 - val_accuracy: 0.5712\n",
      "Epoch 36/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.8046 - accuracy: 0.6961 - val_loss: 1.2419 - val_accuracy: 0.5715\n",
      "Epoch 37/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7838 - accuracy: 0.7076 - val_loss: 1.2698 - val_accuracy: 0.5745\n",
      "Epoch 38/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7789 - accuracy: 0.7053 - val_loss: 1.2962 - val_accuracy: 0.5637\n",
      "Epoch 39/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.7685 - accuracy: 0.7110 - val_loss: 1.2571 - val_accuracy: 0.5776\n",
      "Epoch 40/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7525 - accuracy: 0.7168 - val_loss: 1.2396 - val_accuracy: 0.5804\n",
      "Epoch 41/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.7420 - accuracy: 0.7210 - val_loss: 1.2887 - val_accuracy: 0.5776\n",
      "Epoch 42/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7404 - accuracy: 0.7203 - val_loss: 1.2757 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7262 - accuracy: 0.7267 - val_loss: 1.2984 - val_accuracy: 0.5731\n",
      "Epoch 44/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.7158 - accuracy: 0.7330 - val_loss: 1.2969 - val_accuracy: 0.5823\n",
      "Epoch 45/200\n",
      "449/449 [==============================] - 232s 518ms/step - loss: 0.7094 - accuracy: 0.7366 - val_loss: 1.3205 - val_accuracy: 0.5723\n",
      "Epoch 46/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.7068 - accuracy: 0.7348 - val_loss: 1.3129 - val_accuracy: 0.5720\n",
      "Epoch 47/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.6908 - accuracy: 0.7414 - val_loss: 1.3211 - val_accuracy: 0.5667\n",
      "Epoch 48/200\n",
      "449/449 [==============================] - 255s 568ms/step - loss: 0.6824 - accuracy: 0.7451 - val_loss: 1.3227 - val_accuracy: 0.5748\n",
      "Epoch 49/200\n",
      "449/449 [==============================] - 239s 533ms/step - loss: 0.6728 - accuracy: 0.7454 - val_loss: 1.3253 - val_accuracy: 0.5798\n",
      "Epoch 50/200\n",
      "449/449 [==============================] - 232s 518ms/step - loss: 0.6782 - accuracy: 0.7452 - val_loss: 1.3578 - val_accuracy: 0.5709\n",
      "Epoch 51/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.6691 - accuracy: 0.7497 - val_loss: 1.2997 - val_accuracy: 0.5768\n",
      "Epoch 52/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.6529 - accuracy: 0.7571 - val_loss: 1.3312 - val_accuracy: 0.5743\n",
      "Epoch 53/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.6473 - accuracy: 0.7581 - val_loss: 1.3692 - val_accuracy: 0.5726\n",
      "Epoch 54/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.6393 - accuracy: 0.7625 - val_loss: 1.3766 - val_accuracy: 0.5743\n",
      "Epoch 55/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.6349 - accuracy: 0.7642 - val_loss: 1.3756 - val_accuracy: 0.5701\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 232s 516ms/step - loss: 0.6219 - accuracy: 0.7696 - val_loss: 1.3376 - val_accuracy: 0.5784\n",
      "Epoch 57/200\n",
      "449/449 [==============================] - 231s 514ms/step - loss: 0.6156 - accuracy: 0.7713 - val_loss: 1.3995 - val_accuracy: 0.5695\n",
      "Epoch 58/200\n",
      "449/449 [==============================] - 231s 515ms/step - loss: 0.6072 - accuracy: 0.7746 - val_loss: 1.3976 - val_accuracy: 0.5751\n",
      "Epoch 59/200\n",
      "449/449 [==============================] - 231s 516ms/step - loss: 0.6106 - accuracy: 0.7717 - val_loss: 1.3869 - val_accuracy: 0.5695\n",
      "Epoch 60/200\n",
      "449/449 [==============================] - 232s 516ms/step - loss: 0.6099 - accuracy: 0.7761 - val_loss: 1.3857 - val_accuracy: 0.5723\n",
      "Epoch 61/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5926 - accuracy: 0.7824 - val_loss: 1.4297 - val_accuracy: 0.5768\n",
      "Epoch 62/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.5976 - accuracy: 0.7801 - val_loss: 1.3412 - val_accuracy: 0.5795\n",
      "Epoch 63/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.5825 - accuracy: 0.7859 - val_loss: 1.4105 - val_accuracy: 0.5740\n",
      "Epoch 64/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5774 - accuracy: 0.7841 - val_loss: 1.4554 - val_accuracy: 0.5706\n",
      "Epoch 65/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5735 - accuracy: 0.7894 - val_loss: 1.4382 - val_accuracy: 0.5751\n",
      "Epoch 66/200\n",
      "449/449 [==============================] - 232s 518ms/step - loss: 0.5684 - accuracy: 0.7923 - val_loss: 1.4494 - val_accuracy: 0.5642\n",
      "Epoch 67/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.5551 - accuracy: 0.7926 - val_loss: 1.4651 - val_accuracy: 0.5715\n",
      "Epoch 68/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5562 - accuracy: 0.7970 - val_loss: 1.4647 - val_accuracy: 0.5598\n",
      "Epoch 69/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5542 - accuracy: 0.7967 - val_loss: 1.4449 - val_accuracy: 0.5768\n",
      "Epoch 70/200\n",
      "449/449 [==============================] - 234s 522ms/step - loss: 0.5524 - accuracy: 0.7991 - val_loss: 1.5202 - val_accuracy: 0.5787\n",
      "Epoch 71/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5458 - accuracy: 0.8004 - val_loss: 1.4584 - val_accuracy: 0.5801\n",
      "Epoch 72/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5429 - accuracy: 0.8020 - val_loss: 1.4317 - val_accuracy: 0.5751\n",
      "Epoch 73/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5363 - accuracy: 0.8062 - val_loss: 1.4617 - val_accuracy: 0.5801\n",
      "Epoch 74/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5330 - accuracy: 0.8081 - val_loss: 1.4295 - val_accuracy: 0.5759\n",
      "Epoch 75/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5219 - accuracy: 0.8093 - val_loss: 1.5259 - val_accuracy: 0.5684\n",
      "Epoch 76/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5216 - accuracy: 0.8097 - val_loss: 1.5123 - val_accuracy: 0.5726\n",
      "Epoch 77/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5076 - accuracy: 0.8163 - val_loss: 1.5638 - val_accuracy: 0.5642\n",
      "Epoch 78/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.5152 - accuracy: 0.8154 - val_loss: 1.5365 - val_accuracy: 0.5729\n",
      "Epoch 79/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5155 - accuracy: 0.8112 - val_loss: 1.4929 - val_accuracy: 0.5782\n",
      "Epoch 80/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.5083 - accuracy: 0.8152 - val_loss: 1.5307 - val_accuracy: 0.5701\n",
      "Epoch 81/200\n",
      "449/449 [==============================] - 232s 516ms/step - loss: 0.5050 - accuracy: 0.8186 - val_loss: 1.5374 - val_accuracy: 0.5726\n",
      "Epoch 82/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.5063 - accuracy: 0.8153 - val_loss: 1.4886 - val_accuracy: 0.5712\n",
      "Epoch 83/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.5004 - accuracy: 0.8181 - val_loss: 1.5060 - val_accuracy: 0.5695\n",
      "Epoch 84/200\n",
      "449/449 [==============================] - 232s 518ms/step - loss: 0.4910 - accuracy: 0.8225 - val_loss: 1.5489 - val_accuracy: 0.5801\n",
      "Epoch 85/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.4798 - accuracy: 0.8283 - val_loss: 1.5386 - val_accuracy: 0.5759\n",
      "Epoch 86/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.4819 - accuracy: 0.8262 - val_loss: 1.6064 - val_accuracy: 0.5734\n",
      "Epoch 87/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.4874 - accuracy: 0.8256 - val_loss: 1.5044 - val_accuracy: 0.5715\n",
      "Epoch 88/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.4776 - accuracy: 0.8298 - val_loss: 1.5708 - val_accuracy: 0.5734\n",
      "Epoch 89/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.4744 - accuracy: 0.8311 - val_loss: 1.5794 - val_accuracy: 0.5773\n",
      "Epoch 90/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.4676 - accuracy: 0.8330 - val_loss: 1.5960 - val_accuracy: 0.5656\n",
      "Epoch 91/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.4621 - accuracy: 0.8349 - val_loss: 1.6048 - val_accuracy: 0.5790\n",
      "Epoch 92/200\n",
      "449/449 [==============================] - 232s 517ms/step - loss: 0.4679 - accuracy: 0.8321 - val_loss: 1.6064 - val_accuracy: 0.5690\n",
      "Epoch 93/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.4597 - accuracy: 0.8376 - val_loss: 1.5507 - val_accuracy: 0.5784\n",
      "Epoch 94/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.4581 - accuracy: 0.8388 - val_loss: 1.5684 - val_accuracy: 0.5745\n",
      "Epoch 95/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.4526 - accuracy: 0.8369 - val_loss: 1.5684 - val_accuracy: 0.5726\n",
      "Epoch 96/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.4407 - accuracy: 0.8447 - val_loss: 1.5938 - val_accuracy: 0.5782\n",
      "Epoch 97/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.4451 - accuracy: 0.8446 - val_loss: 1.5909 - val_accuracy: 0.5701\n",
      "Epoch 98/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.4453 - accuracy: 0.8417 - val_loss: 1.6432 - val_accuracy: 0.5634\n",
      "Epoch 99/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.4502 - accuracy: 0.8396 - val_loss: 1.6642 - val_accuracy: 0.5653\n",
      "Epoch 100/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.4383 - accuracy: 0.8437 - val_loss: 1.6139 - val_accuracy: 0.5729\n",
      "Epoch 101/200\n",
      "449/449 [==============================] - 235s 523ms/step - loss: 0.4415 - accuracy: 0.8421 - val_loss: 1.6129 - val_accuracy: 0.5709\n",
      "Epoch 102/200\n",
      "449/449 [==============================] - 235s 523ms/step - loss: 0.4238 - accuracy: 0.8529 - val_loss: 1.6867 - val_accuracy: 0.5687\n",
      "Epoch 103/200\n",
      "449/449 [==============================] - 234s 522ms/step - loss: 0.4198 - accuracy: 0.8511 - val_loss: 1.6016 - val_accuracy: 0.5726\n",
      "Epoch 104/200\n",
      "449/449 [==============================] - 286s 638ms/step - loss: 0.4306 - accuracy: 0.8484 - val_loss: 1.6425 - val_accuracy: 0.5731\n",
      "Epoch 105/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4250 - accuracy: 0.8491 - val_loss: 1.6552 - val_accuracy: 0.5667\n",
      "Epoch 106/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4256 - accuracy: 0.8482 - val_loss: 1.6368 - val_accuracy: 0.5598\n",
      "Epoch 107/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4245 - accuracy: 0.8505 - val_loss: 1.5764 - val_accuracy: 0.5720\n",
      "Epoch 108/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4159 - accuracy: 0.8532 - val_loss: 1.7107 - val_accuracy: 0.5603\n",
      "Epoch 109/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4075 - accuracy: 0.8551 - val_loss: 1.6934 - val_accuracy: 0.5717\n",
      "Epoch 110/200\n",
      "449/449 [==============================] - 305s 680ms/step - loss: 0.4184 - accuracy: 0.8522 - val_loss: 1.5874 - val_accuracy: 0.5740\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 306s 681ms/step - loss: 0.4041 - accuracy: 0.8578 - val_loss: 1.7247 - val_accuracy: 0.5712\n",
      "Epoch 112/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4208 - accuracy: 0.8492 - val_loss: 1.6678 - val_accuracy: 0.5659\n",
      "Epoch 113/200\n",
      "449/449 [==============================] - 307s 683ms/step - loss: 0.4133 - accuracy: 0.8530 - val_loss: 1.6969 - val_accuracy: 0.5737\n",
      "Epoch 114/200\n",
      "449/449 [==============================] - 306s 681ms/step - loss: 0.4104 - accuracy: 0.8564 - val_loss: 1.6544 - val_accuracy: 0.5692\n",
      "Epoch 115/200\n",
      "449/449 [==============================] - 307s 683ms/step - loss: 0.4053 - accuracy: 0.8577 - val_loss: 1.6236 - val_accuracy: 0.5762\n",
      "Epoch 116/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.4017 - accuracy: 0.8583 - val_loss: 1.6503 - val_accuracy: 0.5614\n",
      "Epoch 117/200\n",
      "449/449 [==============================] - 306s 682ms/step - loss: 0.3921 - accuracy: 0.8644 - val_loss: 1.6681 - val_accuracy: 0.5651\n",
      "Epoch 118/200\n",
      "449/449 [==============================] - 309s 687ms/step - loss: 0.3891 - accuracy: 0.8636 - val_loss: 1.7112 - val_accuracy: 0.5756\n",
      "Epoch 119/200\n",
      "449/449 [==============================] - 308s 686ms/step - loss: 0.3948 - accuracy: 0.8625 - val_loss: 1.6524 - val_accuracy: 0.5701\n",
      "Epoch 120/200\n",
      "449/449 [==============================] - 307s 684ms/step - loss: 0.3895 - accuracy: 0.8649 - val_loss: 1.6845 - val_accuracy: 0.5678\n",
      "Epoch 121/200\n",
      "449/449 [==============================] - 1175s 3s/step - loss: 0.3972 - accuracy: 0.8606 - val_loss: 1.7369 - val_accuracy: 0.5701\n",
      "Epoch 122/200\n",
      "449/449 [==============================] - 350s 779ms/step - loss: 0.3848 - accuracy: 0.8650 - val_loss: 1.7544 - val_accuracy: 0.5754\n",
      "Epoch 123/200\n",
      "449/449 [==============================] - 369s 822ms/step - loss: 0.4028 - accuracy: 0.8613 - val_loss: 1.6994 - val_accuracy: 0.5731\n",
      "Epoch 124/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3865 - accuracy: 0.8657 - val_loss: 1.7812 - val_accuracy: 0.5603\n",
      "Epoch 125/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3871 - accuracy: 0.8659 - val_loss: 1.7132 - val_accuracy: 0.5584\n",
      "Epoch 126/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.3813 - accuracy: 0.8659 - val_loss: 1.8150 - val_accuracy: 0.5656\n",
      "Epoch 127/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3793 - accuracy: 0.8683 - val_loss: 1.7532 - val_accuracy: 0.5634\n",
      "Epoch 128/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3804 - accuracy: 0.8658 - val_loss: 1.7551 - val_accuracy: 0.5609\n",
      "Epoch 129/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3782 - accuracy: 0.8693 - val_loss: 1.6997 - val_accuracy: 0.5614\n",
      "Epoch 130/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.3825 - accuracy: 0.8653 - val_loss: 1.7224 - val_accuracy: 0.5765\n",
      "Epoch 131/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3870 - accuracy: 0.8664 - val_loss: 1.6674 - val_accuracy: 0.5720\n",
      "Epoch 132/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3692 - accuracy: 0.8745 - val_loss: 1.7651 - val_accuracy: 0.5656\n",
      "Epoch 133/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.3604 - accuracy: 0.8751 - val_loss: 1.7773 - val_accuracy: 0.5659\n",
      "Epoch 134/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3678 - accuracy: 0.8725 - val_loss: 1.8109 - val_accuracy: 0.5698\n",
      "Epoch 135/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3741 - accuracy: 0.8729 - val_loss: 1.7846 - val_accuracy: 0.5759\n",
      "Epoch 136/200\n",
      "449/449 [==============================] - 235s 524ms/step - loss: 0.3728 - accuracy: 0.8699 - val_loss: 1.8140 - val_accuracy: 0.5690\n",
      "Epoch 137/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.3640 - accuracy: 0.8735 - val_loss: 1.8100 - val_accuracy: 0.5609\n",
      "Epoch 138/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3593 - accuracy: 0.8756 - val_loss: 1.7793 - val_accuracy: 0.5628\n",
      "Epoch 139/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3543 - accuracy: 0.8781 - val_loss: 1.7991 - val_accuracy: 0.5665\n",
      "Epoch 140/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.3618 - accuracy: 0.8738 - val_loss: 1.7445 - val_accuracy: 0.5600\n",
      "Epoch 141/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3585 - accuracy: 0.8762 - val_loss: 1.7982 - val_accuracy: 0.5687\n",
      "Epoch 142/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3509 - accuracy: 0.8790 - val_loss: 1.7711 - val_accuracy: 0.5684\n",
      "Epoch 143/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.3527 - accuracy: 0.8807 - val_loss: 1.8203 - val_accuracy: 0.5667\n",
      "Epoch 144/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3629 - accuracy: 0.8755 - val_loss: 1.7858 - val_accuracy: 0.5656\n",
      "Epoch 145/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3646 - accuracy: 0.8773 - val_loss: 1.7774 - val_accuracy: 0.5698\n",
      "Epoch 146/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3456 - accuracy: 0.8811 - val_loss: 1.7931 - val_accuracy: 0.5723\n",
      "Epoch 147/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3607 - accuracy: 0.8774 - val_loss: 1.7433 - val_accuracy: 0.5723\n",
      "Epoch 148/200\n",
      "449/449 [==============================] - 233s 518ms/step - loss: 0.3534 - accuracy: 0.8759 - val_loss: 1.8273 - val_accuracy: 0.5609\n",
      "Epoch 149/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 1.8211 - val_accuracy: 0.5600\n",
      "Epoch 150/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3541 - accuracy: 0.8765 - val_loss: 1.8351 - val_accuracy: 0.5628\n",
      "Epoch 151/200\n",
      "449/449 [==============================] - 235s 524ms/step - loss: 0.3593 - accuracy: 0.8784 - val_loss: 1.8375 - val_accuracy: 0.5637\n",
      "Epoch 152/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3474 - accuracy: 0.8801 - val_loss: 1.8144 - val_accuracy: 0.5626\n",
      "Epoch 153/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3437 - accuracy: 0.8820 - val_loss: 1.8067 - val_accuracy: 0.5651\n",
      "Epoch 154/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3439 - accuracy: 0.8815 - val_loss: 1.8479 - val_accuracy: 0.5715\n",
      "Epoch 155/200\n",
      "449/449 [==============================] - 234s 521ms/step - loss: 0.3527 - accuracy: 0.8800 - val_loss: 1.8069 - val_accuracy: 0.5651\n",
      "Epoch 156/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3382 - accuracy: 0.8835 - val_loss: 1.8669 - val_accuracy: 0.5639\n",
      "Epoch 157/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3356 - accuracy: 0.8864 - val_loss: 1.8306 - val_accuracy: 0.5609\n",
      "Epoch 158/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3347 - accuracy: 0.8847 - val_loss: 1.8652 - val_accuracy: 0.5653\n",
      "Epoch 159/200\n",
      "449/449 [==============================] - 233s 520ms/step - loss: 0.3429 - accuracy: 0.8834 - val_loss: 1.8730 - val_accuracy: 0.5673\n",
      "Epoch 160/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.3384 - accuracy: 0.8855 - val_loss: 1.8165 - val_accuracy: 0.5653\n",
      "Epoch 161/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3523 - accuracy: 0.8797 - val_loss: 1.7591 - val_accuracy: 0.5667\n",
      "Epoch 162/200\n",
      "449/449 [==============================] - 234s 520ms/step - loss: 0.3402 - accuracy: 0.8836 - val_loss: 1.7952 - val_accuracy: 0.5598\n",
      "Epoch 163/200\n",
      "449/449 [==============================] - 233s 519ms/step - loss: 0.3383 - accuracy: 0.8844 - val_loss: 1.8067 - val_accuracy: 0.5648\n",
      "Epoch 164/200\n",
      "449/449 [==============================] - 238s 530ms/step - loss: 0.3221 - accuracy: 0.8903 - val_loss: 1.8366 - val_accuracy: 0.5578\n",
      "Epoch 165/200\n",
      "449/449 [==============================] - 247s 550ms/step - loss: 0.3288 - accuracy: 0.8891 - val_loss: 1.9366 - val_accuracy: 0.5598\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 239s 533ms/step - loss: 0.3340 - accuracy: 0.8851 - val_loss: 1.8783 - val_accuracy: 0.5690\n",
      "Epoch 167/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3411 - accuracy: 0.8846 - val_loss: 1.8737 - val_accuracy: 0.5573\n",
      "Epoch 168/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3273 - accuracy: 0.8909 - val_loss: 1.8318 - val_accuracy: 0.5584\n",
      "Epoch 169/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3351 - accuracy: 0.8852 - val_loss: 1.8318 - val_accuracy: 0.5520\n",
      "Epoch 170/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3308 - accuracy: 0.8881 - val_loss: 1.8072 - val_accuracy: 0.5620\n",
      "Epoch 171/200\n",
      "449/449 [==============================] - 240s 534ms/step - loss: 0.3314 - accuracy: 0.8891 - val_loss: 1.8402 - val_accuracy: 0.5726\n",
      "Epoch 172/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3197 - accuracy: 0.8931 - val_loss: 1.8628 - val_accuracy: 0.5717\n",
      "Epoch 173/200\n",
      "449/449 [==============================] - 240s 534ms/step - loss: 0.3296 - accuracy: 0.8901 - val_loss: 1.8052 - val_accuracy: 0.5653\n",
      "Epoch 174/200\n",
      "449/449 [==============================] - 239s 533ms/step - loss: 0.3320 - accuracy: 0.8868 - val_loss: 1.8642 - val_accuracy: 0.5720\n",
      "Epoch 175/200\n",
      "449/449 [==============================] - 241s 536ms/step - loss: 0.3050 - accuracy: 0.8979 - val_loss: 1.8896 - val_accuracy: 0.5678\n",
      "Epoch 176/200\n",
      "449/449 [==============================] - 240s 534ms/step - loss: 0.3260 - accuracy: 0.8876 - val_loss: 1.9213 - val_accuracy: 0.5662\n",
      "Epoch 177/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3273 - accuracy: 0.8885 - val_loss: 1.8656 - val_accuracy: 0.5731\n",
      "Epoch 178/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3090 - accuracy: 0.8954 - val_loss: 1.8795 - val_accuracy: 0.5776\n",
      "Epoch 179/200\n",
      "449/449 [==============================] - 240s 534ms/step - loss: 0.3331 - accuracy: 0.8869 - val_loss: 1.8188 - val_accuracy: 0.5776\n",
      "Epoch 180/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3209 - accuracy: 0.8922 - val_loss: 1.8871 - val_accuracy: 0.5773\n",
      "Epoch 181/200\n",
      "449/449 [==============================] - 243s 541ms/step - loss: 0.3218 - accuracy: 0.8928 - val_loss: 1.7724 - val_accuracy: 0.5603\n",
      "Epoch 182/200\n",
      "449/449 [==============================] - 243s 541ms/step - loss: 0.3162 - accuracy: 0.8945 - val_loss: 1.8714 - val_accuracy: 0.5734\n",
      "Epoch 183/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3222 - accuracy: 0.8903 - val_loss: 1.8214 - val_accuracy: 0.5673\n",
      "Epoch 184/200\n",
      "449/449 [==============================] - 243s 541ms/step - loss: 0.3216 - accuracy: 0.8931 - val_loss: 1.8342 - val_accuracy: 0.5706\n",
      "Epoch 185/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3143 - accuracy: 0.8947 - val_loss: 1.8191 - val_accuracy: 0.5653\n",
      "Epoch 186/200\n",
      "449/449 [==============================] - 240s 535ms/step - loss: 0.3227 - accuracy: 0.8913 - val_loss: 1.8557 - val_accuracy: 0.5720\n",
      "Epoch 187/200\n",
      "449/449 [==============================] - 240s 536ms/step - loss: 0.3293 - accuracy: 0.8897 - val_loss: 1.8354 - val_accuracy: 0.5684\n",
      "Epoch 188/200\n",
      "449/449 [==============================] - 241s 536ms/step - loss: 0.3165 - accuracy: 0.8944 - val_loss: 1.8058 - val_accuracy: 0.5717\n",
      "Epoch 189/200\n",
      "449/449 [==============================] - 242s 538ms/step - loss: 0.3071 - accuracy: 0.8963 - val_loss: 1.8472 - val_accuracy: 0.5759\n",
      "Epoch 190/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3052 - accuracy: 0.8966 - val_loss: 1.9027 - val_accuracy: 0.5651\n",
      "Epoch 191/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3176 - accuracy: 0.8917 - val_loss: 1.9145 - val_accuracy: 0.5645\n",
      "Epoch 192/200\n",
      "449/449 [==============================] - 246s 549ms/step - loss: 0.3117 - accuracy: 0.8956 - val_loss: 1.8810 - val_accuracy: 0.5754\n",
      "Epoch 193/200\n",
      "449/449 [==============================] - 241s 537ms/step - loss: 0.3086 - accuracy: 0.8959 - val_loss: 1.8571 - val_accuracy: 0.5723\n",
      "Epoch 194/200\n",
      "449/449 [==============================] - 241s 538ms/step - loss: 0.3266 - accuracy: 0.8888 - val_loss: 1.8218 - val_accuracy: 0.5684\n",
      "Epoch 195/200\n",
      "449/449 [==============================] - 263s 585ms/step - loss: 0.3320 - accuracy: 0.8901 - val_loss: 1.8738 - val_accuracy: 0.5745\n",
      "Epoch 196/200\n",
      "449/449 [==============================] - 312s 694ms/step - loss: 0.3022 - accuracy: 0.8973 - val_loss: 1.8069 - val_accuracy: 0.5687\n",
      "Epoch 197/200\n",
      "449/449 [==============================] - 311s 693ms/step - loss: 0.3154 - accuracy: 0.8941 - val_loss: 1.9695 - val_accuracy: 0.5670\n",
      "Epoch 198/200\n",
      "449/449 [==============================] - 311s 693ms/step - loss: 0.3133 - accuracy: 0.8974 - val_loss: 1.8985 - val_accuracy: 0.5773\n",
      "Epoch 199/200\n",
      "449/449 [==============================] - 312s 694ms/step - loss: 0.3116 - accuracy: 0.8941 - val_loss: 1.8578 - val_accuracy: 0.5673\n",
      "Epoch 200/200\n",
      "449/449 [==============================] - 308s 686ms/step - loss: 0.2962 - accuracy: 0.9010 - val_loss: 1.8380 - val_accuracy: 0.5656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173c989b108>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
